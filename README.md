###### T81-577: Applied Data Science for Practioners
 - Instructor: Asim Banskota, School of Engineering and Applied Science, Washington University in St. Louis
# The Final Project
#### Name: Kunihiro Fujita
==============================
### Project
The analysis of SMS Spam Collection Dataset.<br>
In this study, various classification methos are tried to predict which SMS is ham or spam.<br>
Data Source is below.<br>
https://www.kaggle.com/uciml/sms-spam-collection-dataset<br>
### Business Goal & the aim of this project
From the cyber secuirty perspective, spam/phishing e-mail attack is a typical way of cyberattacks, which can cause serious damages to organizations. Moreover, the more sophisticated spam/phishing e-mails are being developed. Therefore, it is extremely important for an organization to take preventive measures against it and reduce the risk.
Based on such problem awareness, I try to analyze SMS Spam dataset and deepen understanding of it as an information security person.
At the same time, I tyr to apply various algorithms for predictive modeling I've learned through this lecture and improve my skill on them. 

### Comments on using/citing the codes in references in this project
To complete this project, I searched a lot of websites and learned a lot from then. To complete this project, I searched a lot of websites and learned a lot from then. Especially, I've learned very much from the references shown below. To tell the truth, I used/cited their methods in many parts and follow their way basically. In this sense, my original work is limited. Still, I sought to incorporate as much as I could. Besides, I investigated this data set broadly by using 11 algorithms.
In this project, the main personal goal is to acquire basic skills, methods, and concepts that are necessary for developing an effective project and analysis.

### Main Program
The main program is placed under the 'notebooks' directory. The filename is 'Final_Project_0430.ipynb'.

### References
In this project, the analysis and models are based on the following nice sites.<br>
- https://www.kaggle.com/dejavu23/sms-spam-or-ham-beginner
- https://www.kaggle.com/muzzzdy/sms-spam-detection-with-various-classifiers<br>
- https://www.kaggle.com/jcbrooks/airlines-delay-and-cancellation-analysis
## Oath<br>
"The work I submitted represents my work and my work alone.  I abode by the academic integrity policy and I am aware of the consequences associated with engaging in academic misconduct. "

Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    └── tox.ini            <- tox file with settings for running tox; see tox.testrun.org


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
# DS_Project_Kuni
